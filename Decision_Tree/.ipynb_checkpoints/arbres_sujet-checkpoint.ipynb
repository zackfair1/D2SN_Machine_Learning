{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TP : Arbres de décision</center>\n",
    "<center>Prédiction des performances académiques d'un étudiant et interprétation</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Objectifs* : \n",
    "    - Mettre en oeuvre les méthodes relatives aux arbres de décision introduites en cours afin de prédire le\n",
    "    résultat à un examen final du cursus de licence. \n",
    "    - Interpréter ces résultats pour discuter de l'équité du système éducatif considéré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette séance, les librairies suivantes seront utilisées : installez-les si nécessaire et chargez-les. Il sera utile de consulter l'aide de R pour comprendre à quoi correspondent les paramètres et les attributs d'une fonction donnée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "randomForest 4.6-14\n",
      "\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Loaded gbm 2.1.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library('rpart')\n",
    "library('rpart.plot')\n",
    "library('randomForest')\n",
    "library('gbm')\n",
    "library('nnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières\n",
    "\n",
    "<p><div class=\"lev1\"><a href=\"#Jeu-de-données-:-présentation-et-analyse\"><span class=\"toc-item-num\">1 - </span>Jeu de données : présentation et analyse</a></div>\n",
    "<div class=\"lev1\"><a href=\"#Arbre-de-décision\"><span class=\"toc-item-num\">2 - </span>Arbre de décision</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Construction-de-l'arbre\"><span class=\"toc-item-num\">2.1 - </span>Construction de l'arbre</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Elagage\"><span class=\"toc-item-num\">2.2 - </span>Elagage</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Exploitation-des-résultats\"><span class=\"toc-item-num\">2.3 - </span>Exploitation des résultats</a></div>\n",
    "<div class=\"lev1\"><a href=\"#Amélioration-de-la-prédiction\"><span class=\"toc-item-num\">3 - </span>Amélioration de la prédiction</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Bagging-(Bootstrap-AGGregatING)\"><span class=\"toc-item-num\">3.1 - </span>Bagging (Bootstrap AGGregatING)</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Forêts-aléatoires\"><span class=\"toc-item-num\">3.2 - </span>Forêts aléatoires</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Boosting\"><span class=\"toc-item-num\">3.3 - </span>Boosting</a></div>\n",
    "<div class=\"lev1\"><a href=\"#Comparaison\"><span class=\"toc-item-num\">4 - </span>Comparison</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Interprétation\"><span class=\"toc-item-num\">5 - </span>Interprétation</a></div>\n",
    "<div class=\"lev2\"><a href=\"#Références\"><span class=\"toc-item-num\"> </span>Références</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jeu de données : présentation et analyse\n",
    "\n",
    "Cette séance est inspirée des articles <a name=\"ref-1\"/>[(Hussain et al., 2018)](#hussain) et <a name=\"mcdaniel\"/>[(McDaniel, 2018)](#cite-calicoww2:2) et le jeu de données original est disponible sur [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Student+Academics+Performance). Le jeu de données étudié durant cette séance contient $300$ observations de $21$ prédicteurs présentés dans le tableau ci-dessous. Il s'agit de données concernant des étudiants indiens en fin de troisième année de licence (pour faciliter l'interprétation, nous transposons le système d'éducation indien en un équivalent français, avec les inexactitudes que cela peut induire).\n",
    "\n",
    "|Nom  |Description|Valeurs|\n",
    "|-----|-----------|-------|\n",
    "|GE   |Gender  | Male (M)/ Female (F)|\n",
    "|CST  |Caste  | General/SC/ST/OBC/MOBC|\n",
    "|TNP  |Class X Percentage | $[0,1]$ |\n",
    "|TWP  |Class XII Percentage |$[0,1]$ |\n",
    "|IAP  |Internal Assess Percentage |$[0,1]$ |\n",
    "|ARR  |Previous failed test |Yes (Y)/No (N) |\n",
    "|MS   |Marital Status            | Married / Unmarried |\n",
    "|LS   |Live in Town or Village              |Town (T)/Village (V)|\n",
    "|AS   |Admission Category |Free/Paid|\n",
    "|FMI  |Family Monthly Income (in Rupee)|$[0,+\\infty[$|\n",
    "|FS   |Family Size                     |$\\mathbb{N}$|\n",
    "|FQ   |Father Qualification              |Illiterate (Il)/Under Class X (UM)/10/12/Degree/PG|\n",
    "|MQ   |Mother Qualification               |Illiterate (Il)/Under Class X (UM)/10/12/Degree/PG|\n",
    "|FO   |Father Occupation               |Service/Business/Retired/Farmer/Other|\n",
    "|MO   |Mother Occupation               |Service/Business/Retired/Housewife/Other|\n",
    "|NF   |Number of Friends | $\\mathbb{N}$|\n",
    "|SH   |Study Hours |$[0,6]$ (h)|\n",
    "|SS   |Student School Attended at Class X level | Govt./Private|\n",
    "|ME   |Medium|English(Eng.)/Assamese(Asm.)/Hindi(Hin.)/Bengali(Ben.)|\n",
    "|TT   |Home to College Travel Time|$[0,2]$ (h)|\n",
    "|ATD  |Class Attendance Percentage|$[0,1]$|\n",
    "\n",
    "Détails :\n",
    "- `CST` : 'General' désigne les castes qui ne sont pas discriminées. Les $4$ autres désignations (SC:Schelule Caste; ST:Schedule Tribe; OBC:Other Backward Class; MOBC:Minorities and Other Backward Class) recouvrent des classes sociales souvent victimes de discrimination. Par exemple, 'SC' inclut les Dalits, aussi appelés intouchables.\n",
    "- `TNP` et `TWP` : le 'class X exam' est un certificat général de fin d’études secondaires dans le système scolaire indien; pour simplifier, on pourra considérer qu'il est équivalent au brevet des collèges en France. Le 'class XII exam' est un certificat général de fin d’études secondaires supérieures, on pourra considérer qu'il est équivalent au baccalauréat en France. La valeur associée, renormalisée, désigne le pourcentage de bonnes réponse à ces examens. Voir [ici](https://en.wikipedia.org/wiki/Higher_Secondary_School_Certificate) pour plus de détails. \n",
    "- `IAP` : on pourra considérer cette variable comme la note de contrôle continu obtenue durant la licence.\n",
    "- `ARR` : 'Yes' signifie que l'étudiant doit passer des rattrapages.\n",
    "- `FQ` : '10' (resp. 12) désigne la validation de l'examen de class X (resp. XII); 'Degree' un niveau licence ou équivalent et 'PG'un niveau master ou plus.\n",
    "- `ME` : le médium est la langue utilisée pour l'instruction et les examens.\n",
    "\n",
    "La variable à prédire, ou réponse, notée `ESP` est le 'End Semester Percentage' qui est le résultat obtenu à l'examen final pour l'obtention du diplôme de licence. `ESP` prend $2$ valeurs : \n",
    "- 'Pass' lorsque l'étudiant obtient un score de plus de 50%\n",
    "- 'Fail' lorsque l'étudiant obtient un score de moins de 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données sont directement séparées en Train.csv pour l'apprentissage et Test.csv pour la validation.\n",
    "\n",
    "><u>Tâche 1</u> : Importer et visualiser les données : y a-t-il des données manquantes ? aberrantes ? inutiles ? Quelle est la taille de l'ensemble d'apprentissage ? de l'ensemble de test ? Est-ce que cela est cohérent ?\n",
    ">Quelles sont les données :\n",
    ">- quantitatives ? \n",
    ">- qualitatives ordonnées ? \n",
    ">- qualitatives non-ordonnées ? \n",
    ">\n",
    ">La tâche de prédiction relève-t-elle de la régression ou de la classification ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Réponse</u> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision\n",
    "\n",
    "\n",
    "### Construction de l'arbre\n",
    "\n",
    "><u>Tâche 2</u> : Sur l'ensemble d'apprentissage, déterminer l’arbre de décision permettant de prédire la catégorie à partir des variables explicatives en utilisant la fonction `rpart` avec les paramètres par défault (voir [ici](https://stat.ethz.ch/R-manual/R-patched/library/rpart/html/rpart.html)) :\n",
    "- quel critère est minimisé lors d'une coupe ? \n",
    "- combien y a-t-il au minimum d'observations dans chaque feuille ?\n",
    "- à quoi correspond le paramètre `cp` dans `rpart.control`?\n",
    ">\n",
    ">Afficher l'arbre à l'aide de la fonction `rpart.plot`. On considère le nœud terminal (la feuille) $n^o 3$ :\n",
    "- Quelle est la prédiction effectuée ?\n",
    "- Avec quelle probabilité ?\n",
    "- Sur combien d’observations ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=???\n",
    "y_train=???\n",
    "X_test=???\n",
    "y_test=???\n",
    "\n",
    "fit <- rpart(???,data=???)\n",
    "rpart.plot(,??,extra=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Réponse</u> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En classification, on rappelle que la qualité du modèle est mesurée via la précision :\n",
    "$$precision(y,\\hat{y})=\\frac{1}{n}\\sum_{i=1}^n 1_{y_i=\\hat{y}_i}$$\n",
    "où $n$ est la taille de l'ensemble de test, $\\hat{y}_{i}$ la valeur prédite du $i^{ème}$ individu et $y_i$ sa vraie valeur. Le taux d'erreur est donné par $1-precision(y,\\hat{y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 3</u> : Evaluer la qualité du modèle sur les ensembles d'entraînement et de test. Afficher la matrice de confusion et le taux d'erreur de classification pour chacun des ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 4</u> (optionelle): Sur l'ensemble d'apprentissage, pour les deux critères (indice de Gini et entropie), construire un arbre maximal avec (idéalement) une observation par feuille, un arbre avec au plus $m=10$ observations par feuilles et au plus $m=20$ observations par feuilles. Calculer le taux d'erreur pour chaque cas. Empiriquement, pour ce jeu de données, quel critère de coupe est préférable ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Réponse</u> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elagage\n",
    "\n",
    "La qualité de prédiction de l'arbre varie avec le nombre d'observations par feuille.\n",
    "\n",
    "Nous allons dans cette partie chercher de manière plus systématique le meilleur sous-arbre en terme de prédiction. \n",
    "\n",
    "Pour ce faire, nous appliquons la méthode vue en cours, qui consiste, à partir de l'arbre maximal  (voir aussi [ici](http://mlwiki.org/index.php/Cost-Complexity_Pruning)):\n",
    "<ol>\n",
    "<li> Sélectionner une suite de sous-arbres emboîtés et la pénalité $\\alpha$ correspondante via la méthode de <i>cost complexity pruning</i>.</li>\n",
    "<li> Sélectionner le 'meilleur' sous-arbre en effectuant une validation croisée sur les pénalités $\\alpha$.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 5</u> : la méthode `rpart` de R effectue déjà directement les deux points ci-dessus. Les valeurs sont stockées dans l'attribut `cptable` de l'objet arbre fourni. Pour visualiser ces $\\alpha$ et l'erreur correspondante en validation croisée, utiliser la fonction `plotcp`. Donner la valeur $\\alpha$ correspondant au meilleur sous-arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.max <- rpart(???,data=???,control = rpart.control(cp=???, minsplit = ???,minbucket =???))\n",
    "plotcp(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Réponse</u> : On prend $\\alpha=???$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Exploitation des résultats\n",
    "\n",
    "><u>Tâche 6</u> : L'élagage a permi de sélectionner le meilleur sous-arbre. Construire cet arbre à l'aide de la fonction `prune`. Quel est le taux d'erreur de classification de cet arbre sur l'ensemble de test ? Afficher la matrice de confusion. Quel est le nombre de mal classés par l’arbre dans l’échantillon ? Visualiser cet arbre. Quelles sont les trois variables les plus importantes pour la détermination de la catégorie ?\n",
    ">\n",
    "> On considère une nouvelle observation (F,OBS,0.38,0.45,0.49,Y,Unmarried,V,Paid,5720,1,10,Um,Others,Housewife,20,\t3,Govt,Asm,1,0.78) : prédire le résultat de cet étudiant à l'examen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree<-prune(???,cp=???)\n",
    "#insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Réponse</u> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 7</u> (facultatif) : Observer comment les résultats précédents sont impactés (en particulier dans les tâches 6 et 7) si l'on change les échantillons d'entraînement et de test. Comment expliquer ces résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Réponse</u> : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amélioration de la prédiction\n",
    "\n",
    "Nous allons maintenant mettre en place les méthodes de réduction de la variance introduites en cours afin d'améliorer la prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrap AGGregatING)\n",
    "\n",
    "\n",
    "><u>Tâche 8</u> : Rappeler quelle est la différence entre Bagging et Forêt aléatoire. Effectuer une prédiction en utilisant la méthode de Bagging (fonction `randomForest` se trouvant dans la librairie du même nom). Tracer le taux d'erreur sur l'ensemble de test en fonction du nombre d'arbres utilisés. Tracer sur le même graphe le taux d'erreur 'out-of-bag'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_rate<-c()\n",
    "#error_rate_oo<-c()\n",
    "#p=???\n",
    "#Ntrees=c(1,10,30,50,100,200,250,300,400,500,1000,5000)\n",
    "#for(i in Ntrees){\n",
    "#    fit.rf <- randomForest(???, data=???,xtest=???,ytest=???,ntree=??? ,mtry=???, importance=TRUE)\n",
    "#    cm<-fit.rf$confusion\n",
    "#    error_rate_oo<-c(error_rate_oo,???)\n",
    "#    confMat<-fit.rf$test$confusion\n",
    "#    error_rate<-c(error_rate,???)\n",
    "#}\n",
    "#print(error_rate)\n",
    "#plot(Ntrees,error_rate,type='l',col='blue',lwd=2,ylim=c(min(error_rate)-0.1,max(error_rate)+0.1),ylab=\"Error rate\",xlab=\"Number of Trees\")\n",
    "#points(Ntrees,error_rate_oo,type='l',col='red',lwd=2)\n",
    "#legend(\"topright\", legend=c(\"error rate\",\"OOB error\"),lty = c(1,1),col=c(\"blue\",\"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 9</u> : Déterminer quelles sont les variables les plus importantes en utilisant l'attribut `importance` et/ou la fonction `varImpPlot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit.rf<-???\n",
    "#fit.rf$???\n",
    "#varImpPlot(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forêts aléatoires\n",
    "\n",
    "><u>Tâche 10</u> : Effectuer une prédiction en utilisant les forêts aléatoires. Pour différents nombres de variables explicatives échantillonnées $m=\\sqrt{p}$, $m=p/2$ où $p$ est le nombre total de variables explicatives ($p=21$), tracer le taux d'erreur sur l'ensemble de test en fonction du nombre d'arbres utilisés. Tracer sur le même graphe le taux d'erreur 'out-of-bag'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#error_rate<-c()\n",
    "#error_rate_oo<-c()\n",
    "#p=???\n",
    "#Ntrees=c(1,30,50,100,150,200,300,500,1000,5000)\n",
    "#for( m in c(sqrt(p),p/2)){\n",
    "#    for(i in Ntrees){\n",
    "#        fit.rf <- randomForest(???, data=???,xtest=???,ytest=???,ntree=??? ,mtry=???,maxnodes=30, importance=TRUE)\n",
    "#        cm<-fit.rf$confusion\n",
    "#        error_rate_oo<-c(error_rate_oo,???)\n",
    "#        confMat<-fit.rf$test$confusion\n",
    "#        error_rate<-c(error_rate,???)\n",
    "#    }\n",
    "#}\n",
    "#l=length(Ntrees)\n",
    "#plot(Ntrees,error_rate[(1:l)],type='l',col='blue',lwd=2,ylim=c(min(error_rate)-0.1,max(error_rate)+0.1),ylab=\"Error rate\",xlab=\"Number of Trees\")\n",
    "#points(Ntrees,error_rate_oo[(1:l)],type='l',col='blue',lty=2,lwd=2)\n",
    "#points(Ntrees,error_rate[((1+l):(2*l))],type='l',col='red',lwd=2,ylab=\"Error rate\",xlab=\"Number of Trees\")\n",
    "#points(Ntrees,error_rate_oo[((1+l):(2*l))],type='l',col='red',lty=2,lwd=2)\n",
    "#legend(\"topright\", legend=c(\"m=sqrt(p)\",\"m=sqrt(p),OOB\",\"m=p/2\",\"m=p/2,OOB\"),lty = c(1,2,1,2),col=c(\"blue\",\"blue\",\"red\",\"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 11</u> : Déterminer quelles sont les variables les plus importantes en utilisant l'attribut `importance` et/ou la fonction `varImpPlot` pour la méthode de forêt aléatoire la plus performante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "><u>Tâche 12</u> : En utilisant la méthode de boosting, via la fonction `gbm` du package du même nom, contruire une séquence de $5000$ arbres. Calculer le taux d'erreur sur l'ensemble de test. Tracer le taux d'erreur en fonction du nombre d'arbres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train$ESP<-(Train$ESP=='Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_rate3<-c()\n",
    "#error_rate1<-c()\n",
    "#fit3.boost<-gbm(???,data=???,n.trees=5000,interaction.depth = 3)\n",
    "#fit1.boost<-gbm(???,data=???,n.trees=5000,interaction.depth = 1)\n",
    "#for (i in c(1,100,500,1000,5000)){\n",
    "#    pred3.boost <- predict(???, newdata = ???, n.trees =???, type=\"response\")\n",
    "#    labels = (pred3.boost>=0.5)\n",
    "#    cm = table(y_test, labels)\n",
    "#    error_rate3<-c(error_rate3,???)\n",
    "#}\n",
    "#for (i in c(1,100,500,1000,5000)){\n",
    "#    pred1.boost <- predict(???, newdata = ???, n.trees =???, type=\"response\")\n",
    "#    labels = (pred1.boost>=0.5)\n",
    "#    cm = table(y_test, labels)\n",
    "#    error_rate1<-c(error_rate1,???)\n",
    "#}\n",
    "#plot(c(1,100,500,1000,5000),error_rate3,type='l',col='blue',lwd=2,ylim=c(0,1),ylab=\"Error rate\",xlab=\"Number of Trees\")\n",
    "#lines(c(1,100,500,1000,5000),error_rate1,type='l',col='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 13</u> : Utiliser la fonction `summary` pour identifier les variables d'importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(???, n.trees = ???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette dernière partie, on applique une autre méthode de classification à notre jeu de données à titre de comparaison avec les méthodes par arbres en général. On se tourne vers une méthode qui est également adaptée, c'est-à-dire qui est capable de traiter des variables quantitatives et qualitatives non-ordonnées. On choisit la régression logistique multinomiale `multinom` fournie par la librairie `nnet` de R. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "><u>Tâche 14</u> : Effectuer une régression logistique multinomiale sur le jeu de données et déterminer son taux d'erreur sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  40 (39 variable)\n",
      "initial  value 155.958116 \n",
      "iter  10 value 84.299601\n",
      "iter  20 value 69.217007\n",
      "iter  30 value 67.585373\n",
      "iter  40 value 67.548972\n",
      "iter  50 value 67.535012\n",
      "iter  60 value 67.534324\n",
      "final  value 67.534262 \n",
      "converged\n",
      "[1] 0.2133333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Call:\n",
       "multinom(formula = ESP ~ ., data = Train)\n",
       "\n",
       "Coefficients:\n",
       "                   Values    Std. Err.\n",
       "(Intercept) -1.750987e+02 1.883954e-02\n",
       "GEM          2.287231e-01 1.054828e-02\n",
       "CSTMOBC      9.272503e-01 4.597993e-03\n",
       "CSTOBC       1.057380e+00 6.395380e-03\n",
       "CSTSC        1.092455e+00 1.626194e-03\n",
       "CSTST        1.512531e+00 2.257949e-03\n",
       "TNP          8.576651e+00 8.283566e-03\n",
       "TWP          7.744732e+00 9.713205e-03\n",
       "IAP          8.405076e+00 1.170233e-02\n",
       "ARRY        -2.695302e+00 1.585433e-02\n",
       "MSUnmarried  1.617570e+02 1.883954e-02\n",
       "LSV          1.734313e-01 1.960400e-02\n",
       "ASPaid       4.916285e-01 1.418752e-03\n",
       "FMI         -1.899105e-05 3.009895e-05\n",
       "FS           9.120762e-02 6.494524e-02\n",
       "FQ12         1.958665e+00 3.718318e-03\n",
       "FQDegree     2.396967e+00 5.113485e-04\n",
       "FQIl         6.560962e-01 2.904885e-03\n",
       "FQPg        -8.154531e-01 5.987380e-05\n",
       "FQUm         1.356272e-01 1.112195e-02\n",
       "MQ12        -1.379345e+00 1.935796e-03\n",
       "MQDegree     4.144674e+01 0.000000e+00\n",
       "MQIl        -4.572316e-01 3.578931e-03\n",
       "MQPg         6.676101e+00 4.286504e-09\n",
       "MQUm        -1.103290e+00 9.436066e-03\n",
       "FOFarmer    -1.076551e+00 1.332482e-02\n",
       "FOOthers     6.235225e-01 2.194339e-03\n",
       "FORetired    2.334901e+01 0.000000e+00\n",
       "FOService   -1.192937e+00 2.598297e-03\n",
       "MOOthers    -1.626558e+00 4.700440e-04\n",
       "MOService    1.512975e-01 5.777817e-04\n",
       "NF           7.003935e-02 3.810152e-02\n",
       "SH           1.453451e-01 1.172072e-01\n",
       "SSPrivate   -5.759957e-01 6.567138e-03\n",
       "MEBen        2.740115e+01 0.000000e+00\n",
       "MEEng        2.766323e-01 2.607601e-03\n",
       "MEHin        8.821730e+01 0.000000e+00\n",
       "TT           7.607006e-02 2.136338e-02\n",
       "ATD          1.755277e+00 1.488405e-02\n",
       "\n",
       "Residual Deviance: 135.0685 \n",
       "AIC: 213.0685 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fit.glm<-multinom(ESP~.,Train)\n",
    "#pred<-predict(fit.glm,X_test,type='class')\n",
    "#cm = table(y_test, pred)\n",
    "#error_rate<-1-sum(diag(cm))/sum(cm)\n",
    "#print(error_rate)\n",
    "#summary(fit.glm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation\n",
    "\n",
    "Discuter la performance des méthodes testées.\n",
    "\n",
    "Identifier les facteurs de réussite d'un étudiant. En particulier, discuter l'impact des facteurs socio-économiques tels que le sexe, la classe sociale, le revenu et des facteurs éducatifs (école privée ou publique, langue d'enseignement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références \n",
    "\n",
    "<a name=\"mcdaniel\"/> McDaniel, T. (2018) _Using Random Forests to Describe Equity in Higher Education: A Critical Quantitative Analysis of Utah’s Postsecondary Pipelines, Butler Journal of Undergraduate Research: Vol. 4 , Article 10_.\n",
    "\n",
    "<a name=\"hussain\"/> Hussain, S., Dahan, N. A., Ba-Alwib, F. M., & Ribata, N . (2018) _Educational data mining and analysis of students’ academic performance using WEKA. Indonesian Journal of Electrical Engineering and Computer Science, 9(2), 447-459._."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
